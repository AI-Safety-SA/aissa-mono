## 

[**2025	2**](#2025)

[Courses	2](#courses)

[June 12-week AI Safety Fundamentals Course \- Governance, Economics, and Alignment streams (on-going)	2](#june-12-week-ai-safety-fundamentals-course---governance,-economics,-and-alignment-streams-\(on-going\))

[Intro to Transformative AI Course \- May	2](#intro-to-transformative-ai-course---may)

[Intro to Cooperative AI Course by the Cooperative AI Foundation (first official in-person cohort ever)	3](#intro-to-cooperative-ai-course-by-the-cooperative-ai-foundation-\(first-official-in-person-cohort-ever\))

[BlueDot’s Intro to Transformative AI Course (first official in-person cohort ever) \- February	3](#bluedot’s-intro-to-transformative-ai-course-\(first-official-in-person-cohort-ever\)---february)

[University Groups	3](#university-groups)

[Seeded AI Safety University of Witwatersrand (AI Safety WITS)	3](#seeded-ai-safety-university-of-witwatersrand-\(ai-safety-wits\))

[Seeded Stellenbosch AI Safety (Stellies AI Safety)	3](#seeded-stellenbosch-ai-safety-\(stellies-ai-safety\))

[Events	3](#events)

[Talks	3](#talks)

[Notable Meetups	4](#notable-meetups)

[Highlighted Individual Impacts	4](#highlighted-individual-impacts)

[Research	5](#research)

[HumanAgencyBench	5](#humanagencybench)

[UK AISI Bounties	5](#uk-aisi-bounties)

[Precursors, Proxies, and Predictive Models for Long-Horizon Tasks	6](#precursors,-proxies,-and-predictive-models-for-long-horizon-tasks)

[UK AISI Challenge Fund	6](#uk-aisi-challenge-fund)

[**2024	7**](#2024)

[Co-working Space	7](#co-working-space)

[Website	7](#website)

[Newsletter	7](#newsletter)

[Courses	8](#courses-1)

[AI Safety Fundamentals Course	8](#ai-safety-fundamentals-course)

[Events	9](#events-1)

[Workshops	9](#workshops)

[Deep Learning IndabaX (July 2024): AGI Horizons: Utopia, Dystopia, and Everything in-Between	9](#deep-learning-indabax-\(july-2024\):-agi-horizons:-utopia,-dystopia,-and-everything-in-between)

[Deep Learning IndabaX (July 2024): An Introduction to AI-Risk, Key Concepts in AI Safety	10](#deep-learning-indabax-\(july-2024\):-an-introduction-to-ai-risk,-key-concepts-in-ai-safety)

[EA South Africa x AI Safety Cape Town (May 2024): AI Safety Virtual Workshop (Pilot)	11](#ea-south-africa-x-ai-safety-cape-town-\(may-2024\):-ai-safety-virtual-workshop-\(pilot\))

[IndabaXS (March 2024): AI Safety Roundtable	11](#indabaxs-\(march-2024\):-ai-safety-roundtable)

[Meetups	12](#meetups)

[Reading Groups	12](#reading-groups)

[Retreat	12](#retreat)

[**2023	13**](#2023)

[SACAIR (November 2023): AI Safety Tutorial	13](#sacair-\(november-2023\):-ai-safety-tutorial)

[IndabaXS: AI Risk and Opportunity in Africa	13](#indabaxs:-ai-risk-and-opportunity-in-africa)

[Deep Learning IndabaX (July 2023): AI Safety and Governance Workshop	13](#deep-learning-indabax-\(july-2023\):-ai-safety-and-governance-workshop)

# 

# **2025** {#2025}

## **Courses** {#courses}

### **June 12-week AI Safety Fundamentals Course \- Governance, Economics, and Alignment streams (on-going)** {#june-12-week-ai-safety-fundamentals-course---governance,-economics,-and-alignment-streams-(on-going)}

### **Intro to Transformative AI Course \- May** {#intro-to-transformative-ai-course---may}

* Of the 36 people that were accepted to the course, 24 completed it  
  * 33% dropout rate, which is generally expected for these kinds of courses.   
  * This is good because most of those enrolled are full-time professionals (72% either work full-time or are self-employed)  
* **Overall course average: 9.5/10**  
* Highest rated course components sections:  
  * facilitator guidance and participant interactions  
* Lowest rated course components:  
  * Project phase \- likely not enough support and too little time (but it is only a 1 week course after all) \- still rated 8.8/10  
* Participants mentioned that they would appreciate content tailored to the African context. We've done this in previous, longer courses, as you can [see in week 5 of the curriculum here](https://docs.google.com/document/u/0/d/1PK-531ONYFIFFPY_lCDr0WkwFacobaiXsbGtDngHz8w/mobilebasic), but would like to build on this. We think the following topics would be appropriate to include:  
  * The state of AI governance in Africa.  
  * AI preparedness in Africa.  
  * Benefit sharing schemes.  
  * AI sovereignty in Africa.  
  * Threat modelling around AI misuse, including autonomous weapons, surveillance, and mass manipulation.  
* Impact:  
  * Four of the people that completed the course have now joined for our 12-week AISF course.  

### **Intro to Cooperative AI Course by the Cooperative AI Foundation (first official in-person cohort ever)** {#intro-to-cooperative-ai-course-by-the-cooperative-ai-foundation-(first-official-in-person-cohort-ever)}

[Intro to Cooperative AI Course - AISSA Q2 2025 Cohort](https://docs.google.com/document/d/1aS0ub27xRzMCdt25InzHwYey2PzU96tYuIOKaEQ42mg/edit?usp=sharing)

### **BlueDot’s Intro to Transformative AI Course (first official in-person cohort ever) \- February** {#bluedot’s-intro-to-transformative-ai-course-(first-official-in-person-cohort-ever)---february}

We hosted a 5-day course in collaboration with BlueDot at our coworking offices at Innovation City. 

One of the participants wrote up his experience of the course here, another quit his job to work on AI Safety, and another is joining our research group to work with us on a research project. 

## **University Groups** {#university-groups}

### **Seeded AI Safety University of Witwatersrand (AI Safety WITS)** {#seeded-ai-safety-university-of-witwatersrand-(ai-safety-wits)}

**Hosted First Meetup**

\~23 people attended the event. One person provided feedback on the feedback form, rating the event 10/10. 

### **Seeded Stellenbosch AI Safety (Stellies AI Safety)** {#seeded-stellenbosch-ai-safety-(stellies-ai-safety)}

**Elected community organisers**

* Boyd Kane (Lead)  
* Nicholas Lombard

**Hosted First Meetup**

\~12 people attended the session. Feedback forms were not provided. 

## **Events** {#events}

### **Talks** {#talks}

**Cooperative AI Talk and Discussion**

Hosted a Cooperative AI Foundation Fellow, Claude Formanek at our co-working space. Had \~20 attendees. 

### **Notable Meetups** {#notable-meetups}

**AI Governance Faculty Meetup Early 2025** 

Hosted a dinner with top AI governance faculty in Cape Town. Had 2 professors, a postdoc, and a researcher from a national think tank attend. This dinner spurred interest for further discussion and research collaboration with members of our community. 

## **Highlighted Individual Impacts** {#highlighted-individual-impacts}

* Charl Botha \- previous Full Stack Engineer, [https://www.linkedin.com/in/botha-charl/](https://www.linkedin.com/in/botha-charl/)   
  * Joined our in-person BlueDot Intro to Transformative AI course  
  * Quit his job to work on AI Safety  
  * Completed the Intro to Cooperative AI Course  
  * Now an Infrastructure Developer for AI Safety South Africa  
* Jaco Du Toit \- Data Scientist, [https://www.linkedin.com/in/jaco-du-toit-a04785208/](https://www.linkedin.com/in/jaco-du-toit-a04785208/)   
  * Joined the Condor Camp in 2024  
  * Quit his job to work on AI Safety  
  * Joined our team developing evals for the UK AISI alongside the AI Safety Engineering Taskforce.  
  * Completed the Intro to Cooperative AI Course  
  * Attended the Cooperative AI Summer School.   
  * A recipient for a UK AISI Science of Evals Challenge Fund grant   
* Josh Stein \- Software Engineer, [https://www.linkedin.com/in/josh-s-5b4ab869/](https://www.linkedin.com/in/josh-s-5b4ab869/)   
  * Joined the Condor Camp in 2024  
  * Joined our in-person BlueDot Intro to Transformative AI course  
  * Contracted with METR, Equistamp, and the AI Safety Engineering Taskforce.  
  * Now a software engineer for BlueDot Impact.   
* Daniel Samuelson \- ML Engineer, [https://www.linkedin.com/in/daniel-samuelson-20b36a1b2/](https://www.linkedin.com/in/daniel-samuelson-20b36a1b2/)   
  * Joined the Condor Camp in 2024  
  * Pivoted from ML engineering to research engineering with our   
  * Contributed significantly to HumanAgencyBench, a research paper led by Benjamin Sturgeon, which was accepted as a workshop paper to AAAI.   
* Noah De Nicola, Reinforcement Learning MSc Student, [https://www.linkedin.com/in/noah-de-nicola-9626b2218/](https://www.linkedin.com/in/noah-de-nicola-9626b2218/)   
  * Joined the Condor Camp in 2024  
  * Joined our team developing evals for the UK AISI alongside the AI Safety Engineering Taskforce.  
  * AI Safety Fundamentals Course Facilitator   
* Benjamin Sturgeon, Strategic Director of AISSA, [https://www.linkedin.com/in/benjamin-sturgeon-41221241/?originalSubdomain=za](https://www.linkedin.com/in/benjamin-sturgeon-41221241/?originalSubdomain=za)  
  * Was accepted to MATS 8.0 and the MATS extension program under Oly Sourbut and Sid Black’s (UK AISI) stream.   
* Genevieve Chikwanha, Compute Science Student at the University of Cape Town [https://www.linkedin.com/in/g%C3%A9nevieve-chikwanha-7202511b4/?originalSubdomain=za](https://www.linkedin.com/in/g%C3%A9nevieve-chikwanha-7202511b4/?originalSubdomain=za)    
  * Joined our Condor Camp in 2024  
  * Now an AISF course facilitator for us.   
  * Now conducting research on the risks of AI startups as a research assistant under Clifford Shearing at the Global Risk Governance group at the University of Cape Town.    
* Tegan Green, Event Curator at AISSA, [https://www.linkedin.com/in/tegan-green-484510158](https://www.linkedin.com/in/tegan-green-484510158)   
  * Joined the Intro to Cooperative AI Course in Q2 2025  
  * Now an event curator for us, and applying to be a mentor for AI Safety Camp 

## **Research** {#research}

### **HumanAgencyBench** {#humanagencybench}

B. Sturgeon, L. Hyams, D. Samuelson, E. Vorster, J. Haimes, and J. R. Anthis, “HumanAgencyBench: Do Language Models Support Human Agency?,” presented at the Workshop on Datasets and Evaluators of AI Safety, Feb. 2025\. Accessed: Jul. 13, 2025\. \[Online\]. Available: [https://openreview.net/forum?id=nHp5FquS2R](https://openreview.net/forum?id=nHp5FquS2R) 

### **UK AISI Bounties** {#uk-aisi-bounties}

J. Du Toit, L. Hyams, A. Strickland Cooper, and J. Olive, Synthetic Environment Detection Eval, Accepted by the UK AISI for the ARA Stream Bounty Programme, March. 2025\. Available upon request. 

N. De Nicola, L. Hyams, B. Sturgeon, J. Du Toit, J. Bailey, and A. Abbas, Situational Awareness Eval, Accepted by the UK AISI for the ARA Stream Bounty Programme, March. 2025, Available upon request.

J. Du Toit, L. Hyams, and C. Waggoner, RL Manipulation Eval, Accepted by the UK AISI for the ARA Stream Bounty Programme, March. 2025\. Available upon request. 

J. Du Toit, L. Hyams, and C. Waggoner, Efficient Test-Time Chain of Thought Eval, Accepted by the UK AISI for the ARA Stream Bounty Programme, March. 2025\. Available upon request. 

### **Precursors, Proxies, and Predictive Models for Long-Horizon Tasks** {#precursors,-proxies,-and-predictive-models-for-long-horizon-tasks}

J. Du Toit, L. Hyams, D. Anisimov, and S. Brown, “Precursors, Proxies, and Predictive Models for Long-Horizon Tasks.” accepted to the Workshop on Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling at NeurIPS 2025\. Available upon request. 

### **UK AISI Challenge Fund** {#uk-aisi-challenge-fund}

Leo Hyams, Jaco Du Toit, and Samuel Brown were awarded a 99,999 GBP grant by the UK AISI’s Challenge Fund program in Q4 2025 for their work: Proxies for Efficient Evaluation of Autonomous Replication and Adaptation in AI Agents. This work will be completed in partnership with the UK AISI’s Science of Evaluations team. 

# **2024**  {#2024}

## **Co-working Space** {#co-working-space}

We established a co-working space at [Innovation City](https://innovationcity.co.za/) in October which can house up to 6 of our community members. On Wednesday afternoons we are regularly fully booked, before we host our reading group in one of the boardrooms.

Innovation City is becoming an important partner for our organisation, as they have been providing access to media channels for public communication, and seem to actively want to support our mission. They also have varied and large event spaces that we use to run our talks, workshops, and reading groups in.

## **Website** {#website}

We built our website to house our newsletter and to enable greater outreach and credibility. 

Website: [www.aisafetyct.co](http://www.aisafetyct.com)[m](http://www.aisafetyct.com) 

## **Newsletter** {#newsletter}

We published 3 articles at the end of 2024, these received minor attention through our mailing list (which was around \~60 people at the end of 2024), but have since moved the newsletter to Substack so we can track metrics, feedback (via comments) and subscribers better.  

## **Courses** {#courses-1}

### **AI Safety Fundamentals Course**  {#ai-safety-fundamentals-course}

We ran this course from the beginning of march to mid-may. It included both a governance and a technical alignment track. Both tracks were based on the BlueDot AISF Course, but with the governance track being slightly edited to include a section on AI Governance in Africa.  You can find the governance curriculum [here](https://docs.google.com/document/d/1PK-531ONYFIFFPY_lCDr0WkwFacobaiXsbGtDngHz8w/edit?usp=sharing), and the technical alignment curriculum [here](https://docs.google.com/document/d/1ZwR2rhlQClLwxyzVTnWv_ntwQXFzc057IXePUX2SLKc/edit#heading=h.s5znjvp3l4zi). 

We had 208 applicants, of which we accepted 106 participants. However, since some participants elected to do both courses, we accepted 39 participants to our technical track and 92 to our governance track. This resulted in a total of 18 cohorts (6 technical and 12 governance) of 5-8 participants each.

**Demographics of accepted participants:**

We had a total of 74 of participants complete the course (20 technical participants and 54 governance participants). We are still awaiting feedback for this, but preliminary feedback seems good. 

Although we had a good completion rates and some projects come out of the course, we could have been more targeted about our marketing campaign so as to target a better spread of the universities we are interested in. 

**Research Projects**

We will be hosting a presentation of our participants projects on the 30th of June, these include: 

- **The Emerging Ethical Landscape: AI Proliferation and Readiness in Africa**  
  - Collaborators: Chialuka Prisca-mary Onuoha, Winnie Kungu, Uzoma Mkparu  
- **Impacts on human agency from LLMs**  
  - Collaborators: Benjamin Sturgeon  
- **AI Safety Cape Town: Fellowship Retrospective**  
  - Collaborators: Leo Hyams  
- **Cross-Border AI Governance \- A Focus on East, West, and South Africa**  
  - Collaborators: Derrick Mandela, Nkurunziza Christophe, Quency Otieno, Jane ombiro, Maxwell Ouya  
- **AI as a Transformative Tool in Promoting Access in Kenya’s Criminal Justice System**     
  - Collaborators: Michael Mutinda  
- **Sustainable AI and Rethinking AI Ethics and Governance for a Global Context from Principles to Local Realities of Global South**  
  - Collaborators: Merve Ayyuce Kizrak, Mashael Alzaid, Kojo Apeagyei  
- **Exploring AI Governance Education and Opportunities in the Global South**  
  - Collaborators: Chialuka Prisca-mary Onuoha  
- **The Geopolitics of AI in Africa: AI Governance in Critical “National Security” Areas in Africa amid the recent dynamics in geopolitics and regional blocks**   
  - Collaborators: Cosmas Ondino  
- **State of AI Governance in Healthcare in Kenya**  
  - Collaborators: Aurelia Brazeal, Walter Nyagah  
- **AI-Enhanced Food Loss Reduction and Circular Systems for Climate Action in Kenya**      
  -   
- **Advanced AI Regulation: A Dual Framework for Comprehensive Oversight**  
  - Collaborators: Tendai Mikioni

**Feedback** 

- “This was a great initiative. Great job to everyone involved in organizing, tutoring, and monitoring this program. Your efforts are not unnoticed. “ \- Lois Moses (Research Staff, Pan-African Centre for AI Ethics) 

## **Events** {#events-1}

### **Workshops** {#workshops}

#### Deep Learning IndabaX (July 2024): AGI Horizons: Utopia, Dystopia, and Everything in-Between {#deep-learning-indabax-(july-2024):-agi-horizons:-utopia,-dystopia,-and-everything-in-between}

This was a 1.5-hour-long panel discussion featuring: 

- Leo Hyams   
- Benjamin Sturgeon   
- Professor Benjamin Rosman (Professor of AI at the University of Witwatersrand)   
- Lydia De Lange (Executive Director of the Deep Learning IndabaX South Africa)  
- Joshua Maumela (Senior Machine Learning Engineer at Vodacom) 

The panel was a wide-ranging discussion polling experts and people of influence in AI about the state and trajectory of the field. 

Attendees: 100-150

Feedback: 

- 23 responses  
- 4 / 5 rating on average  
- Overall, a very engaging event, but Vodacom guy had a bit of an odd perspective and the session overally could have used more structure 

#### Deep Learning IndabaX (July 2024): An Introduction to AI-Risk, Key Concepts in AI Safety {#deep-learning-indabax-(july-2024):-an-introduction-to-ai-risk,-key-concepts-in-ai-safety}

This 2 hour workshop involved 3 components: talks from presenters, a guided discussion, and then a facilitated reading group: 

*Talks:*

- Ben Sturgeon spoke about how AI is developing rapidly and how to think about the risk landscape.   
- Leo Hyams introduced key concepts in AI Safety like alignment, instrumental convergents, mesa-optimizer, and some research directions like mechanistic interpretability and evaluations.   
- Ahmed Ghoor spoke about researching agent behaviors in gridworlds.

*Discussion:*

- Participants were grouped into sets of \~6, and then told to discuss a questions amongst themselves (such as, “How do you think AI risks could impact society in the short term vs. the long term?”). They discussed for \~10 minutes, and then had a participant report the insights to the broader group.   
- We iterated on this format 3 times. 

*Facilitated Paper Reading:* 

- We read the paper Feature Visualization by Chris Olah, and discussed it as a group.

*Attendees:* \~50

*Feedback:*

- 5 responses  
- 8.2 / 10 rating on average  
- Great session overall, but the paper was a bit too technical for some. 

#### EA South Africa x AI Safety Cape Town (May 2024): AI Safety Virtual Workshop (Pilot)  {#ea-south-africa-x-ai-safety-cape-town-(may-2024):-ai-safety-virtual-workshop-(pilot)}

This 1,5 hour virtual workshop involved:

- An overview of the field and a description of the current state of the field, with facilitated interactive components.   
- This virtual workshop served as a pilot for a fairly standard virtual workshop we plan to run on a regular basis.  
- Participants: \~10

#### IndabaXS (March 2024): AI Safety Roundtable {#indabaxs-(march-2024):-ai-safety-roundtable}

This 3 hour workshop involved:

- A broad overview and introduction to technical AI safety with interactive components, delving into the core debates around the relationship between intelligence and morality, how AI will impact democracy, and the challenges around creating aligned systems.   
- Participants \~15

Quotes:

- “Thank you for hosting this event. It was incredible to be in a space that nurture conversions and knowledge sharing around AI Safety” \- Simone Renga (Data Scientist, Sand Technologies)

### **Meetups** {#meetups}

We have run a couple casual meetups for those interested in AI Safety in Cape Town. These generally consist of a meal and some guided discussion points. We generally have \~12 participants at these meetups, drawn from our community. We could do a better job of getting feedback from these, but the sentiment is overall very positive. 

### **Reading Groups** {#reading-groups}

We’ve been running weekly reading groups on Wednesdays at our co-working space. These attract \~8 participants on average, with a majority of regulars and a few new faces each week. 

### **Retreat** {#retreat}

We ran a retreat with the Condor Initiative. This retreat brought together 24 of the top South African AI safety talent (both technical and governance), prominent South African ML professors, and international AI Safety experts together for a 9-day intensive networking and upskilling event. A notable outcome of this retreat was the interest in forming AI Safety postdoc positions at the nascent University of Cape Town AI Institute and University of the Witwatersrand Machine Intelligence and Neural Discovery (MIND) Institute. 

You can see the Condor Initiative’s comprehensive qualitative and quantitative reports of the retreat here: 

* [Copy of Condor Camp South Africa, quantitative 2024 ](https://docs.google.com/document/d/11o_IbFYfEnF52GHhFMzU7YDNVSJv42ak3NIACBQCk1Q/edit?usp=sharing)  
* [Copy of Condor Camp South Africa 2024 (Qualitative Analysis) ](https://docs.google.com/document/d/1VAgaLQjU3K6myIKJkMBRn6uiXmRwcXe8MzGOdj-PvcE/edit?tab=t.0#heading=h.qah534e7sogi)

# 

# **2023** {#2023}

### **SACAIR (November 2023): AI Safety Tutorial**  {#sacair-(november-2023):-ai-safety-tutorial}

This 2 hour workshop involved:

- A broad overview and introduction to technical AI safety with interactive red teaming exercises (presented by Benjamin Sturgeon and Leo Hyams)  
- Participants: \~30  
- We did not produce feedback forms for this event.

### **IndabaXS: AI Risk and Opportunity in Africa** {#indabaxs:-ai-risk-and-opportunity-in-africa}

This involved breakout groups into AI risk, AI for Good, and AI in Africa, followed by a general discussion. 

Participants: \~15

We did not produce feedback forms for this event. 

### **Deep Learning IndabaX (July 2023): AI Safety and Governance Workshop** {#deep-learning-indabax-(july-2023):-ai-safety-and-governance-workshop}

This 2,5 hour workshop involved:

- A guided walkthrough of the African safety landscape (presented by Jonas Kgomo)  
- Perspectives on AI governance in Africa (presented by Zainab Chirwa)  
- An introduction to AI safety (presented by Benjamin Sturgeon).   
- There were roughly 40 participants at the workshop  
- We did not produce feedback forms for this event.